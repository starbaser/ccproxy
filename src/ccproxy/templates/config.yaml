# See https://docs.litellm.ai/docs/proxy/configs
model_list:
  # Default model
  - model_name: default
    litellm_params:
      model: claude-sonnet-4-5-20250929

  # Anthropic provided claude models, no `api_key` needed
  - model_name: claude-sonnet-4-5-20250929
    litellm_params:
      model: anthropic/claude-sonnet-4-5-20250929
      api_base: https://api.anthropic.com

  - model_name: claude-opus-4-5-20251101
    litellm_params:
      model: anthropic/claude-opus-4-5-20251101
      api_base: https://api.anthropic.com

  - model_name: claude-haiku-4-5-20251001
    litellm_params:
      model: anthropic/claude-haiku-4-5-20251001
      api_base: https://api.anthropic.com

  - model_name: claude-3-5-haiku-20241022
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_base: https://api.anthropic.com

litellm_settings:
  force_stream: true
  callbacks:
    - ccproxy.handler
    - langfuse
  success_callback:
    - langfuse

general_settings:
  forward_client_headers_to_llm_api: true
  # Set high limits - proxy-level rate limiting not needed for local use
  max_parallel_requests: 1000000
  global_max_parallel_requests: 1000000
